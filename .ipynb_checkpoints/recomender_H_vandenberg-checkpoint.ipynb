{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e962f6c",
   "metadata": {},
   "source": [
    "# Content Based Filtering\n",
    "https://www.analyticsvidhya.com/blog/2021/12/comprehensive-project-on-building-a-movie-recommender-website/\n",
    "\n",
    "Recommender System is basically a system that takes the userâ€™s choice as input and predicts all the related movies, or news, books, etc.\n",
    "\n",
    "you would have seen Recommender System in Action while Scrolling on Youtube, Netflix, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aced0de6",
   "metadata": {},
   "source": [
    "Content-based filtering\n",
    "This type of Filtering system recommends you on the basis of what you actually like. Imagine you love to watch comedy movies so a content-based recommender system will recommend you other related comedy movies which belong to your category"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad934879",
   "metadata": {},
   "source": [
    "Steps Involved\n",
    "\n",
    "- Step 1. Getting the Dataset\n",
    "\n",
    "- Step 2. Data Cleaning and Processing\n",
    "\n",
    "- Step 3. Training our Recommender System\n",
    "\n",
    "- Step 4. Testing and Validation\n",
    "\n",
    "- Step 5. Saving the Trained Model for Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b37cb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd7e63c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "\n",
    "movies = pd.read_csv('data/movies.csv')\n",
    "#imbd_df = pd.read_csv('data/imdb_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72e000ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                               title  \\\n",
       "0        1                    Toy Story (1995)   \n",
       "1        2                      Jumanji (1995)   \n",
       "2        3             Grumpier Old Men (1995)   \n",
       "3        4            Waiting to Exhale (1995)   \n",
       "4        5  Father of the Bride Part II (1995)   \n",
       "\n",
       "                                        genres  \n",
       "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "1                   Adventure|Children|Fantasy  \n",
       "2                               Comedy|Romance  \n",
       "3                         Comedy|Drama|Romance  \n",
       "4                                       Comedy  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f3e1d4",
   "metadata": {},
   "source": [
    " ## Training Steps\n",
    " \n",
    " our final data frame is textual data, we need to parse it into numerical or floating values in order to feed as inputs in machine learning algorithms. This process is called feature extraction |  vectorization)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47094db",
   "metadata": {},
   "source": [
    "## Data Processing Function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8831b30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbca7bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "\n",
    "movies = pd.read_csv('data/movies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f12b8940",
   "metadata": {},
   "outputs": [],
   "source": [
    "def content_data_processing(df):\n",
    "    \n",
    "    genres = df['genres']\n",
    "    genres = [genre.split(\"|\") for genre in genres]\n",
    "    df['genre_corpus']= genres\n",
    "    df['genre_corpus'] = df.genre_corpus.apply(lambda x:\" \".join(x))\n",
    "    cvect = CountVectorizer() \n",
    "    vectors = cvect.fit_transform(df['genre_corpus']).toarray()\n",
    "    #print(vectors.shape)\n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b97d62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "46726b1c",
   "metadata": {},
   "source": [
    "### Model Building :\n",
    "\n",
    "our model should be capable of finding the similarity between movies based on their tags.\n",
    "\n",
    "Our Recommender model takes a movie title as input and predicts top-n most similar movies based on the tags\n",
    "\n",
    "here we will use the concept of Cosine distance to calculate the similarity of tags\n",
    "\n",
    "sklearn provides a class for calculating pairwise cosine_similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f1995e",
   "metadata": {},
   "source": [
    "## Function for Contentent Based filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "802f389d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def content_model(movie_list, top_n):\n",
    "\n",
    "    new_df = movies.copy()\n",
    "    \n",
    "       \n",
    "    movie_index_1 = new_df[new_df['title'] == movie_list[0]].index[0]\n",
    "    movie_index_2 = new_df[new_df.title == movie_list[1]].index[0]\n",
    "    movie_index_3 =  new_df[new_df.title == movie_list[2]].index[0]\n",
    "    \n",
    "    df_1 = new_df.sample(frac = 0.5)\n",
    "    df_2 = new_df.iloc[[movie_index_1,movie_index_2,movie_index_3]]\n",
    "    df_2 = df_2.append(df_1)\n",
    "    \n",
    "    vectors = content_data_processing(df_2)\n",
    "    similarity = cosine_similarity(vectors)\n",
    "    \n",
    "    distances_1 = similarity[0]\n",
    "    distances_2 = similarity[1]\n",
    "    distances_3 = similarity[2]\n",
    "    \n",
    "    sim_score_1 = pd.Series(distances_1).sort_values(ascending = False)\n",
    "    sim_score_2 = pd.Series(distances_2).sort_values(ascending = False)\n",
    "    sim_score_3 = pd.Series(distances_3).sort_values(ascending = False)\n",
    "    \n",
    "    # Getting the indexes of the 10 most similar movies\n",
    "    sim_score_list = sim_score_1.append(sim_score_2).append(sim_score_3).sort_values(ascending = False)\n",
    "\n",
    "\n",
    "    # Appending the names of movies\n",
    "    indexes = list(sim_score_list.index)\n",
    "    \n",
    "    recommended_movies = []\n",
    "    \n",
    "    top_n = 10\n",
    "    for i in indexes:\n",
    "        \n",
    "        if df_2.iloc[i].title not in movie_list and len(recommended_movies) < top_n:\n",
    "            recommended_movies.append(df_2.iloc[i].title)\n",
    "    \n",
    "        \n",
    "    return recommended_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0a77cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_list = ['Guardian Angel (1994)','Jack Frost (1979)','Wasteland No. 1: Ardent Verdant (2017)']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c71d3d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "recommended_movies = content_model(movie_list, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89bdfe72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Caged No More (2016)',\n",
       " \"President's Man: A Line in the Sand, The (2002)\",\n",
       " 'Firepower (1979)',\n",
       " 'Deadly Encounter (1982)',\n",
       " 'Eraser (1996)',\n",
       " 'Assassination (2015)',\n",
       " 'Moscow Heat (2004)',\n",
       " 'Killer Elite, The (1975)',\n",
       " 'Klansman, The (1974)',\n",
       " 'Operation Thunderbolt (1977)']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommended_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a76f95b",
   "metadata": {},
   "source": [
    "# Collaborative Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28844864",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pickle\n",
    "import copy\n",
    "from surprise import Reader, Dataset, SVD\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from surprise.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc1fa2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv('data/movies.csv')\n",
    "ratings = pd.read_csv('data/train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416a5baf",
   "metadata": {},
   "source": [
    "### Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10b13e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Movies dataset: 62423 rows\n",
      "Length of Ratings dataset: 10000038 rows\n"
     ]
    }
   ],
   "source": [
    "print('Length of Movies dataset:', movies.shape[0],'rows')\n",
    "print('Length of Ratings dataset:', ratings.shape[0],'rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4363cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = ratings.drop('timestamp',axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9529e7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = ratings.sample(frac = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b1b606a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the reader variable\n",
    "\n",
    "reader = Reader(rating_scale=(1,5))\n",
    "data = Dataset.load_from_df(ratings,reader)\n",
    "\n",
    "# Instantiate the model\n",
    "SVD_model = SVD()\n",
    "\n",
    "\n",
    "# Train Test Split method\n",
    "X_train, X_test = train_test_split(data,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3fbd820e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x22ea455e040>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model to our data\n",
    "\n",
    "SVD_model.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5907467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict \n",
    "\n",
    "predictions = SVD_model.test(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e6422c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8341\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8341035926026377"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the accuracy of our model\n",
    "\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5bc722b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc6790ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(SVD_model, open('SVD_model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39032e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train data into subset to save as smaller csv file to be able\n",
    "# to upload to github, concat files to use again\n",
    "\n",
    "ratings_1 = ratings[0:2500000]\n",
    "ratings_2 = ratings[2500000:5000000]\n",
    "ratings_3 = ratings[5000000:7500000]\n",
    "ratings_4 = ratings[7500000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "696b0b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_1.to_csv('data/ratings_1.csv', index=False)\n",
    "ratings_2.to_csv('data/ratings_2.csv', index=False)\n",
    "ratings_3.to_csv('data/ratings_3.csv', index=False)\n",
    "ratings_4.to_csv('data/ratings_4.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c107ed4",
   "metadata": {},
   "source": [
    "## Kaggle submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47f03d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Kaggle submission\n",
    "\n",
    "test = pd.read_csv('data/test.csv')\n",
    "\n",
    "# Make predictions on test data\n",
    "pred_list = []\n",
    "\n",
    "for _,row in test.iterrows():\n",
    "    x = (SVD_model.predict(row.userId, row.movieId))\n",
    "    pred = x[3]\n",
    "    pred_list.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "48d1d4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert values to strings\n",
    "\n",
    "test['userId'] = test['userId'].astype(str)\n",
    "test['movieId'] = test['movieId'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "58699a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission column\n",
    "\n",
    "test['Id'] = test['userId'] +'_'+test['movieId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5672fbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame({'Id':test['Id'],\n",
    "                              'rating':pred_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c3a00c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv('SVD_model_sub.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8011c10",
   "metadata": {},
   "source": [
    "## Function for Streamlit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "878f98ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing data\n",
    "movies_df = pd.read_csv('data/movies.csv')\n",
    "\n",
    "ratings_1 = pd.read_csv('data/ratings_1.csv')\n",
    "ratings_2 = pd.read_csv('data/ratings_2.csv')\n",
    "ratings_3 = pd.read_csv('data/ratings_3.csv')\n",
    "ratings_4 = pd.read_csv('data/ratings_4.csv')\n",
    "\n",
    "# Add ratings together to form complete dataset\n",
    "\n",
    "ratings_df = ratings_1.append(ratings_2).append(ratings_3).append(ratings_4)\n",
    "\n",
    "ratings_df.drop(['timestamp'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d742f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We make use of an SVD model trained on the MovieLens 10 million dataset.\n",
    "model=pickle.load(open('SVD_model.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b983f8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_item(item_id):\n",
    "    \"\"\"Map a given favourite movie to users within the\n",
    "       MovieLens dataset with the same preference.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    item_id : int\n",
    "        A MovieLens Movie ID.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        User IDs of users with similar high ratings for the given movie.\n",
    "\n",
    "    \"\"\"\n",
    "    # Data preprosessing\n",
    "    reader = Reader(rating_scale=(0, 5))\n",
    "    load_df = Dataset.load_from_df(ratings_df,reader)\n",
    "    a_train = load_df.build_full_trainset()\n",
    "\n",
    "    predictions = []\n",
    "    for ui in a_train.all_users():\n",
    "        predictions.append(model.predict(iid=item_id,uid=ui, verbose = False))\n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27bbcf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_movies(movie_list):\n",
    "    \"\"\"Maps the given favourite movies selected within the app to corresponding\n",
    "    users within the MovieLens dataset.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    movie_list : list\n",
    "        Three favourite movies selected by the app user.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        User-ID's of users with similar high ratings for each movie.\n",
    "\n",
    "    \"\"\"\n",
    "    # Store the id of users\n",
    "    id_store=[]\n",
    "    # For each movie selected by a user of the app,\n",
    "    # predict a corresponding user within the dataset with the highest rating\n",
    "    for i in movie_list:\n",
    "        predictions = prediction_item(item_id = i)\n",
    "        predictions.sort(key=lambda x: x.est, reverse=True)\n",
    "        # Take the top 10 user id's from each movie with highest rankings\n",
    "        for pred in predictions[:10]:\n",
    "            id_store.append(pred.uid)\n",
    "    # Return a list of user id's\n",
    "    return id_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa361ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collab_model(movie_list,top_n):\n",
    "    \"\"\"Performs Collaborative filtering based upon a list of movies supplied\n",
    "       by the app user.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    movie_list : list (str)\n",
    "        Favorite movies chosen by the app user.\n",
    "    top_n : type\n",
    "        Number of top recommendations to return to the user.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list (str)\n",
    "        Titles of the top-n movie recommendations to the user.\n",
    "\n",
    "    \"\"\"\n",
    "    top_n=10\n",
    "    new_df = movies_df.copy()\n",
    "    new_df.set_index('movieId',inplace=True)\n",
    "    \n",
    "    indices = pd.Series(new_df['title'])\n",
    "    users_ids = pred_movies(movie_list)\n",
    "    \n",
    "    # Get movie IDs and ratings for top users\n",
    "    df_init_users = ratings_df[ratings_df['userId']==users_ids[0]]\n",
    "    for i in users_ids[1:]:\n",
    "        df_init_users = df_init_users.append(ratings_df[ratings_df['userId']==i])\n",
    "    \n",
    "    # Include predictions for chosen movies\n",
    "    for j in movie_list:\n",
    "        a = pd.DataFrame(prediction_item(j))\n",
    "        for i in set(df_init_users['userId']):\n",
    "            mid = indices[indices == j].index[0]\n",
    "            est = a['est'][a['uid']==i].values[0]\n",
    "            df_init_users = df_init_users.append(pd.Series([int(i),int(mid),est], index=['userId','movieId','rating']), ignore_index=True)\n",
    "    \n",
    "    # Remove duplicate entries\n",
    "    df_init_users.drop_duplicates(inplace=True)\n",
    "    \n",
    "    #Create pivot table\n",
    "    util_matrix = df_init_users.pivot_table(index=['userId'], columns=['movieId'], values='rating')\n",
    "    \n",
    "    # Fill Nan values with 0's and save the utility matrix in scipy's sparse matrix format\n",
    "    util_matrix.fillna(0, inplace=True)\n",
    "    util_matrix_sparse = sp.sparse.csr_matrix(util_matrix.values)\n",
    "    \n",
    "    # Compute the similarity matrix using the cosine similarity metric\n",
    "    user_similarity = cosine_similarity(util_matrix_sparse.T)\n",
    "    \n",
    "    # Save the matrix as a dataframe to allow for easier indexing\n",
    "    user_sim_df = pd.DataFrame(user_similarity, index = util_matrix.columns, columns = util_matrix.columns)\n",
    "    user_similarity = cosine_similarity(np.array(df_init_users), np.array(df_init_users))\n",
    "    user_sim_df = pd.DataFrame(user_similarity, index = df_init_users['movieId'].values.astype(int), columns = df_init_users['movieId'].values.astype(int))\n",
    "    \n",
    "    # Remove duplicate rows from matrix\n",
    "    user_sim_df = user_sim_df.loc[~user_sim_df.index.duplicated(keep='first')]\n",
    "    \n",
    "    # Transpose matrix\n",
    "    user_sim_df = user_sim_df.T\n",
    "    \n",
    "    # Find IDs of chosen load_movie_titles\n",
    "    idx_1 = indices[indices == movie_list[0]].index[0]\n",
    "    idx_2 = indices[indices == movie_list[1]].index[0]\n",
    "    idx_3 = indices[indices == movie_list[2]].index[0]\n",
    "    \n",
    "    # Creating a Series with the similarity scores in descending order\n",
    "    distances_1 = user_sim_df[idx_1]\n",
    "    distances_2 = user_sim_df[idx_2]\n",
    "    distances_3 = user_sim_df[idx_3]\n",
    "    \n",
    "    # Calculating the scores\n",
    "    sim_score_1 = pd.Series(distances_1).sort_values(ascending = False)\n",
    "    sim_score_2 = pd.Series(distances_2).sort_values(ascending = False)\n",
    "    sim_score_3 = pd.Series(distances_3).sort_values(ascending = False)\n",
    "    \n",
    "    # Appending the names of movies\n",
    "    sim_score_list = sim_score_1.append(sim_score_2).append(sim_score_3).sort_values(ascending = False)\n",
    "    \n",
    "    # Choose top 50\n",
    "    top_50_indexes = list(sim_score_list.iloc[1:50].index)\n",
    "    \n",
    "    # Removing chosen movies\n",
    "    indexes = np.setdiff1d(top_50_indexes,[idx_1,idx_2,idx_3])\n",
    "    \n",
    "    # Get titles of recommended movies\n",
    "    recommended_movies = []\n",
    "    for i in indexes[:top_n]:\n",
    "        recommended_movies.append(list(movies_df[movies_df['movieId']==i]['title']))\n",
    "    \n",
    "    # Return list of movies\n",
    "    recommended_movies = [val for sublist in recommended_movies for val in sublist]\n",
    "    return recommended_movies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6a439f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Shanghai Triad (Yao a yao yao dao waipo qiao) (1995)',\n",
       " 'Twelve Monkeys (a.k.a. 12 Monkeys) (1995)',\n",
       " 'Dead Man Walking (1995)',\n",
       " 'Cry, the Beloved Country (1995)',\n",
       " 'Georgia (1995)',\n",
       " 'Indian in the Cupboard, The (1995)',\n",
       " \"Don't Be a Menace to South Central While Drinking Your Juice in the Hood (1996)\",\n",
       " 'Lawnmower Man 2: Beyond Cyberspace (1996)',\n",
       " 'Two Bits (1995)',\n",
       " 'Big Bully (1996)']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_list = ['Guardian Angel (1994)','Jack Frost (1979)','Wasteland No. 1: Ardent Verdant (2017)']\n",
    "collab_model(movie_list,top_n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce5845d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fb87f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb96e2c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407b64db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931b834e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baeec171",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e11c77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b37fdfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8a6ac2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35192b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31116ca3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
